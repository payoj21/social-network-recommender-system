{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import *\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import *\n",
    "import sys\n",
    "import pickle\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (34130, 3)\n"
     ]
    }
   ],
   "source": [
    "file_dir = '../data/Ciao/'\n",
    "pos_file = open(file_dir+\"/positive_feedback_dataframe.pkl\",'rb')\n",
    "soc_file = open(file_dir+\"/social_positive_feedback_dataframe.pkl\",'rb')\n",
    "P = positive_df = pickle.load(pos_file)\n",
    "SP = social_positive_df = pickle.load(soc_file)\n",
    "print('data dimension: \\n', positive_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(data):\n",
    "    for col in ('item', 'user', 'rating'):\n",
    "        data[col] = data[col].astype('category')\n",
    "    \n",
    "    code_user = dict(zip(data['user'].cat.codes, data['user']))\n",
    "    user_code = dict(zip(data['user'], data['user'].cat.codes))\n",
    "    code_item = dict(zip(data['item'].cat.codes, data['item']))\n",
    "    item_code = dict(zip(data['item'], data['item'].cat.codes))\n",
    "    \n",
    "    mappings = {'code_user' : code_user, 'user_code' : user_code, 'code_item' : code_item, 'item_code' : item_code}\n",
    "\n",
    "    ratings = csr_matrix((data['rating'], (data['user'].cat.codes, data['item'].cat.codes)))\n",
    "    ratings.eliminate_zeros()\n",
    "    return ratings, data, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, df, mappings = create_matrix(positive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_train_test(ratings, test_size = 0.2, seed = 1234):\n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    "\n",
    "    # Dictionary Of Keys based sparse matrix is more efficient\n",
    "    # for constructing sparse matrices incrementally compared with csr_matrix\n",
    "    train = ratings.copy().todok()\n",
    "    test = dok_matrix(train.shape)\n",
    "    \n",
    "    # for all the users assign randomly chosen interactions\n",
    "    # to the test and assign those interactions to zero in the training;\n",
    "    # when computing the interactions to go into the test set, \n",
    "    # remember to round up the numbers (e.g. a user has 4 ratings, if the\n",
    "    # test_size is 0.2, then 0.8 ratings will go to test, thus we need to\n",
    "    # round up to ensure the test set gets at least 1 rating)\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size = n_splits, replace = False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "    \n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2104x10768 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 29673 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = create_train_test(X, test_size = 0.1, seed = 20191004)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, P, SP):\n",
    "        self.P = P\n",
    "        self.SP = SP\n",
    "        \n",
    "    def static(self, social = False):\n",
    "        user = np.random.choice(self.P['user'])\n",
    "        \n",
    "        items = {}\n",
    "        \n",
    "        items['P'] = np.random.choice(self.P.query('user == @user')['item'])\n",
    "        tot_items = set(self.P['item'])\n",
    "        if social:\n",
    "            df_sp = list(self.SP.query('user == @user')['item'])\n",
    "            if(len(df_sp)):\n",
    "                items['SP'] = np.random.choice(df_sp)\n",
    "\n",
    "        \n",
    "        pos_items = []\n",
    "        for key in items:\n",
    "            pos_items.append(items[key])\n",
    "        \n",
    "        neg_items = list(tot_items - set(pos_items))\n",
    "                \n",
    "        items['N'] = np.random.choice(neg_items)\n",
    "        \n",
    "        return user, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mappings(code, key):\n",
    "    return code[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, df_train = create_matrix(train, users_col, items_col, ratings_col, threshold)\n",
    "# X_test, df_test = create_matrix(test, users_col, items_col, ratings_col, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(model, ratings):\n",
    "    \"\"\"\n",
    "    computes area under the ROC curve (AUC).\n",
    "    The full name should probably be mean\n",
    "    auc score as it is computing the auc\n",
    "    for every user's prediction and actual\n",
    "    interaction and taking the average for\n",
    "    all users\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : BPR instance\n",
    "        Trained BPR model\n",
    "        \n",
    "    ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        sparse matrix of user-item interactions\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    auc : float 0.0 ~ 1.0\n",
    "    \"\"\"\n",
    "    auc = 0.0\n",
    "    \n",
    "    n_users, n_items = ratings.shape\n",
    "    for user, row in enumerate(ratings):\n",
    "        y_pred = model._predict_user(user)\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[row.indices] = 1\n",
    "        auc += roc_auc_score(y_true, y_pred)\n",
    "    auc /= n_users\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(ratings, test_size = 0.2, seed = 1234):\n",
    "    \"\"\"\n",
    "    split the user-item interactions matrix into train and test set\n",
    "    by removing some of the interactions from every user and pretend\n",
    "    that we never seen them\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        The user-item interactions matrix\n",
    "    \n",
    "    test_size : float between 0.0 and 1.0, default 0.2\n",
    "        Proportion of the user-item interactions for each user\n",
    "        in the dataset to move to the test set; e.g. if set to 0.2\n",
    "        and a user has 10 interactions, then 2 will be moved to the\n",
    "        test set\n",
    "    \n",
    "    seed : int, default 1234\n",
    "        Seed for reproducible random splitting the \n",
    "        data into train/test set\n",
    "    \n",
    "    Returns\n",
    "    ------- \n",
    "    train : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        Training set\n",
    "    \n",
    "    test : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        Test set\n",
    "    \"\"\"\n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    "\n",
    "    # Dictionary Of Keys based sparse matrix is more efficient\n",
    "    # for constructing sparse matrices incrementally compared with csr_matrix\n",
    "    train = ratings.copy().tocsr()\n",
    "    test = csr_matrix(train.shape)\n",
    "    \n",
    "    # for all the users assign randomly chosen interactions\n",
    "    # to the test and assign those interactions to zero in the training;\n",
    "    # when computing the interactions to go into the test set, \n",
    "    # remember to round up the numbers (e.g. a user has 4 ratings, if the\n",
    "    # test_size is 0.2, then 0.8 ratings will go to test, thus we need to\n",
    "    # round up to ensure the test set gets at least 1 rating)\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size = n_splits, replace = False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "    \n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2104x10768 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 33944 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = create_train_test(X, test_size = 0.1, seed = 20191004)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2104, 10768)\n",
      "4271\n"
     ]
    }
   ],
   "source": [
    "print (X_test.shape)\n",
    "print (X_test.getnnz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2104, 10768)\n",
      "33944\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_train.getnnz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBPR2:\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking (BPR) for implicit feedback data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate : float, default 0.01\n",
    "        learning rate for gradient descent\n",
    "\n",
    "    n_factors : int, default 20\n",
    "        Number/dimension of user and item latent factors\n",
    "\n",
    "    n_iters : int, default 15\n",
    "        Number of iterations to train the algorithm\n",
    "        \n",
    "    batch_size : int, default 1000\n",
    "        batch size for batch gradient descent, the original paper\n",
    "        uses stochastic gradient descent (i.e., batch size of 1),\n",
    "        but this can make the training unstable (very sensitive to\n",
    "        learning rate)\n",
    "\n",
    "    reg : int, default 0.01\n",
    "        Regularization term for the user and item latent factors\n",
    "\n",
    "    seed : int, default 1234\n",
    "        Seed for the randomly initialized user, item latent factors\n",
    "\n",
    "    verbose : bool, default True\n",
    "        Whether to print progress bar while training\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    user_factors : 2d ndarray, shape [n_users, n_factors]\n",
    "        User latent factors learnt\n",
    "\n",
    "    item_factors : 2d ndarray, shape [n_items, n_factors]\n",
    "        Item latent factors learnt\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme \n",
    "    Bayesian Personalized Ranking from Implicit Feedback\n",
    "    - https://arxiv.org/abs/1205.2618\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate = 0.01, n_factors = 15, n_iters = 10, batch_size = 1, \n",
    "                 social_coefficient = 1, reg_u = 0.015, reg_i = 0.025, reg_k = 0.025, reg_j = 0.025, seed = 1234, verbose = True):\n",
    "        self.reg_u = reg_u\n",
    "        self.reg_i = reg_i\n",
    "        self.reg_k = reg_k\n",
    "        self.reg_j = reg_j\n",
    "        self.s_uk = social_coefficient\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # to avoid re-computation at predict\n",
    "        self._prediction = None\n",
    "        \n",
    "    def fit(self, ratings, sampler):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions\n",
    "        \"\"\"\n",
    "        n_users, n_items = ratings.shape\n",
    "        batch_size = self.batch_size\n",
    "        if n_users < batch_size:\n",
    "            batch_size = n_users\n",
    "            sys.stderr.write('WARNING: Batch size is greater than number of users,'\n",
    "                             'switching to a batch size of {}\\n'.format(n_users))\n",
    "\n",
    "        batch_iters = n_users // batch_size\n",
    "        \n",
    "        # initialize random weights\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.user_factors = rstate.normal(size = (n_users, self.n_factors))\n",
    "        self.item_factors = rstate.normal(size = (n_items, self.n_factors))\n",
    "        \n",
    "        # progress bar for training iteration if verbose is turned on\n",
    "        loop = range(self.n_iters)\n",
    "        if self.verbose:\n",
    "            loop = trange(self.n_iters, desc = self.__class__.__name__)\n",
    "        self.auc_scores = []\n",
    "        for _ in loop:\n",
    "            for _ in range(batch_iters):\n",
    "                user, items = sampler.static(True)\n",
    "                sampled_users = np.zeros(self.batch_size, dtype = np.int)\n",
    "                sampled_users[0] = get_mappings(mappings['user_code'], user)\n",
    "                \n",
    "                sampled_pos_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "                sampled_pos_items[0] = get_mappings(mappings['item_code'], items['P'])\n",
    "                \n",
    "                \n",
    "                sampled_soc_pos_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "                if 'SP' in items:\n",
    "                    sampled_soc_pos_items[0] = get_mappings(mappings['item_code'], items['SP'])\n",
    "                else:\n",
    "                    sampled_soc_pos_items[0] = -1\n",
    "                \n",
    "                \n",
    "                sampled_neg_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "                sampled_neg_items[0] = get_mappings(mappings['item_code'], items['N'])\n",
    "                \n",
    "                self._update(sampled_users, sampled_pos_items, sampled_soc_pos_items, sampled_neg_items)\n",
    "            self.auc_scores.append(auc_score(sbpr2, X_test))\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _update(self, u, i, k ,j):\n",
    "        \"\"\"\n",
    "        update according to the bootstrapped user u, \n",
    "        positive item i and negative item j\n",
    "        \"\"\"\n",
    "        user_u = self.user_factors[u]\n",
    "        item_i = self.item_factors[i]\n",
    "        item_j = self.item_factors[j]\n",
    "        if k != -1:\n",
    "            item_k = self.item_factors[k]\n",
    "        else:\n",
    "            item_k = 0\n",
    "        \n",
    "        # decompose the estimator, compute the difference between\n",
    "        # the score of the (positive and social items) and (social and negative items) ; \n",
    "\n",
    "        r_ukj = np.sum(user_u * (item_k - item_j), axis = 1)\n",
    "        sigmoid_ukj = np.exp(-r_ukj) / (1.0 + np.exp(-r_ukj))     # derivation of 1/(1+exp(-x))\n",
    "        \n",
    "        r_uik = np.sum(user_u*(item_i - item_k), axis = 1)/(1 + self.s_uk)\n",
    "        sigmoid_uik = np.exp(-r_uik) / (1.0 + np.exp(-r_uik))     # derivation of 1/(1+exp(-x))\n",
    "        \n",
    "        # repeat the 1 dimension sigmoid n_factors times so\n",
    "        # the dimension will match when doing the update\n",
    "        \n",
    "        sigmoid_uik_tiled = np.tile(sigmoid_uik, (self.n_factors, 1)).T\n",
    "        sigmoid_ukj_tiled = np.tile(sigmoid_ukj, (self.n_factors, 1)).T\n",
    "        \n",
    "\n",
    "        # update using gradient descent\n",
    "\n",
    "        grad_u = sigmoid_uik_tiled * ((item_k - item_i)/(1 + self.s_uk)) + sigmoid_ukj_tiled * (item_j - item_k) + self.reg_u * user_u\n",
    "        grad_i = sigmoid_uik_tiled * (-user_u)/(1 + self.s_uk) + self.reg_i * item_i\n",
    "        grad_k = sigmoid_uik_tiled * (user_u/(1 + self.s_uk)) + (sigmoid_ukj_tiled * -user_u) + self.reg_k * item_k\n",
    "        grad_j = (sigmoid_ukj_tiled * user_u) + self.reg_j * item_j\n",
    "        \n",
    "        self.user_factors[u] -= self.learning_rate * grad_u\n",
    "        self.item_factors[i] -= self.learning_rate * grad_i\n",
    "        self.item_factors[k] -= self.learning_rate * grad_k\n",
    "        self.item_factors[j] -= self.learning_rate * grad_j\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Obtain the predicted ratings for every users and items\n",
    "        by doing a dot product of the learnt user and item vectors.\n",
    "        The result will be cached to avoid re-computing it every time\n",
    "        we call predict, thus there will only be an overhead the first\n",
    "        time we call it. Note, ideally you probably don't need to compute\n",
    "        this as it returns a dense matrix and may take up huge amounts of\n",
    "        memory for large datasets\n",
    "        \"\"\"\n",
    "        if self._prediction is None:\n",
    "            self._prediction = self.user_factors.dot(self.item_factors.T)\n",
    "\n",
    "        return self._prediction\n",
    "\n",
    "    def _predict_user(self, user):\n",
    "        \"\"\"\n",
    "        returns the predicted ratings for the specified user,\n",
    "        this is mainly used in computing evaluation metric\n",
    "        \"\"\"\n",
    "        user_pred = self.user_factors[user].dot(self.item_factors.T)\n",
    "        return user_pred\n",
    "    \n",
    "    def recommend(self, data, N = 5):\n",
    "        \"\"\"\n",
    "        Returns the top N ranked items for given user id,\n",
    "        excluding the ones that the user already liked\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions \n",
    "        \n",
    "        N : int, default 5\n",
    "            top-N similar items' N\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        recommendation : 2d ndarray, shape [number of users, N]\n",
    "            each row is the top-N ranked item for each query user\n",
    "        \"\"\"\n",
    "        n_users = data.shape[0]\n",
    "        recommendation = np.zeros((n_users, N))\n",
    "        scores = np.zeros((n_users, N))\n",
    "        users = []\n",
    "        ranks = []\n",
    "        for user in range(n_users):\n",
    "            users.append([user]*N)\n",
    "            ranks.append([i for i in range(1,N+1)])\n",
    "            topN_items, topN_scores = self.recommend_user(data, user, N)\n",
    "            recommendation[user], scores[user] = topN_items, topN_scores\n",
    "\n",
    "        return recommendation, scores, users, ranks\n",
    "    \n",
    "    def get_item_ratings(self, data, u):\n",
    "        \n",
    "        if u not in self.item_ratings:\n",
    "            items = data[u].indices\n",
    "            ratings = data[u].data\n",
    "            \n",
    "            self.item_ratings[u] = []\n",
    "            for i in range(len(items)):\n",
    "                self.item_ratings[u].append((items[i], ratings[i]))\n",
    "                \n",
    "        return self.item_ratings[u]\n",
    "        \n",
    "\n",
    "    def recommend_user(self, data, u, N, validation = True):\n",
    "        \"\"\"the top-N ranked items for a given user\"\"\"\n",
    "        scores = self._predict_user(u)\n",
    "\n",
    "        # compute the top N items, removing the items that the user already liked\n",
    "        # from the result and ensure that we don't get out of bounds error when \n",
    "        # we ask for more recommendations than that are available\n",
    "        liked = set(data[u].indices)\n",
    "        count = N + len(liked)\n",
    "        if count < scores.shape[0]:\n",
    "\n",
    "            # when trying to obtain the top-N indices from the score,\n",
    "            # using argpartition to retrieve the top-N indices in \n",
    "            # unsorted order and then sort them will be faster than doing\n",
    "            # straight up argort on the entire score\n",
    "            # http://stackoverflow.com/questions/42184499/cannot-understand-numpy-argpartition-output\n",
    "            ids = np.argpartition(scores, -count)[-count:]\n",
    "            best_ids = np.argsort(scores[ids])[::-1]\n",
    "            best = ids[best_ids]\n",
    "            best_scores = scores[best]\n",
    "        else:\n",
    "            best = np.argsort(scores)[::-1]\n",
    "            best_scores = scores[best]    \n",
    "\n",
    "        topN_items = []\n",
    "        topN_scores = []\n",
    "        for i in range(len(best)):\n",
    "            if best[i] not in liked:\n",
    "                topN_items.append(best[i])\n",
    "                topN_scores.append(best_scores[i])\n",
    "                \n",
    "        topN_items = list(islice((item for item in topN_items), N))\n",
    "        topN_scores = list(islice((score for score in topN_scores), N))\n",
    "        return topN_items, topN_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sample(positive_df, social_positive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SBPR2:   0%|                                                                                                               | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   1%|█                                                                                                      | 1/100 [00:22<37:56, 22.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   2%|██                                                                                                     | 2/100 [00:45<37:22, 22.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   3%|███                                                                                                    | 3/100 [01:09<37:21, 23.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   4%|████                                                                                                   | 4/100 [01:31<36:47, 23.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   5%|█████▏                                                                                                 | 5/100 [01:54<36:19, 22.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   6%|██████▏                                                                                                | 6/100 [02:17<35:52, 22.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   7%|███████▏                                                                                               | 7/100 [02:40<35:25, 22.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   8%|████████▏                                                                                              | 8/100 [03:03<35:01, 22.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:   9%|█████████▎                                                                                             | 9/100 [03:26<34:44, 22.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:  10%|██████████▏                                                                                           | 10/100 [03:49<34:29, 23.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:  11%|███████████▏                                                                                          | 11/100 [04:12<34:14, 23.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:  12%|████████████▏                                                                                         | 12/100 [04:35<33:56, 23.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:  13%|█████████████▎                                                                                        | 13/100 [04:59<33:38, 23.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:  14%|██████████████▎                                                                                       | 14/100 [05:22<33:17, 23.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "SBPR2:  15%|███████████████▎                                                                                      | 15/100 [05:46<33:02, 23.33s/it]\u001b[A\u001b[A/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:134: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f3404235d041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                 'n_factors': 10}\n\u001b[1;32m      9\u001b[0m \u001b[0msbpr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSBPR2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msbpr2_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msbpr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-54c6e5f0e2d4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, ratings, sampler)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_pos_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_soc_pos_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_neg_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msbpr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-d33a91947af6>\u001b[0m in \u001b[0;36mauc_score\u001b[0;34m(model, ratings)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mauc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mn_users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         fpr, tpr, tresholds = roc_curve(y_true, y_score,\n\u001b[0;32m--> 272\u001b[0;31m                                         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# parameters were randomly chosen\n",
    "sbpr2_params = {'reg_u': 0.025,\n",
    "                'reg_i': 0.025,\n",
    "                'reg_k' : 0.025,\n",
    "                'reg_j' : 0.025,\n",
    "                'learning_rate': 0.3,\n",
    "                'n_iters': 100,\n",
    "                'n_factors': 10}\n",
    "sbpr2 = SBPR2(**sbpr2_params)\n",
    "sbpr2.fit(X_train, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "auc = sbpr2.auc_scores\n",
    "x = range(len(auc))\n",
    "plt.plot(x,auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "auc = sbpr2.auc_scores\n",
    "x = range(len(auc))\n",
    "plt.plot(x,auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recommendation, scores, users, ranks = bpr.recommend(X_test, N = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-d651d1318065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommendation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rank'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame({'user': flatten(users), 'item': flatten(recommendation), 'score': flatten(scores), 'rank': flatten(ranks)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['item'] = df_test['item'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>69963</td>\n",
       "      <td>14.722504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31660</td>\n",
       "      <td>14.636142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>58681</td>\n",
       "      <td>14.338766</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>93133</td>\n",
       "      <td>14.136444</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>105175</td>\n",
       "      <td>14.023970</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user    item      score  rank\n",
       "0     1   69963  14.722504     1\n",
       "1     1   31660  14.636142     2\n",
       "2     1   58681  14.338766     3\n",
       "3     1   93133  14.136444     4\n",
       "4     1  105175  14.023970     5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(columns = ['user_id', 'item_id', 'rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [i+1 for i in range(X_test_np.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [i+1 for i in range(X_test_np.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24174 111869\n"
     ]
    }
   ],
   "source": [
    "print (len(users), len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test_data.txt', 'w+')\n",
    "for user in users:\n",
    "    for item in items:\n",
    "        line = str(user) + ' ' + str(item) + ' ' + str(X_test_np[user-1][item-1]) + '\\n'\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['rating'] = test_ratings\n",
    "test_data['user'] = users\n",
    "test_data['item'] = items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, als, item_knn as knn\n",
    "from lenskit import topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['user', 'item', 'rating']\n",
    "df_test.columns = ['user', 'item', 'score', 'rank']\n",
    "df_test['Algorithm'] = ['BPR']*len(df_test['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = np.array(df['rating']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg = topn.ndcg(df_test, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_at_5 = topn.recall(df_test, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_at_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_5 = topn.precision(df_test, test_data)\n",
    "precision_at_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
