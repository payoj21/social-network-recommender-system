{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import *\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import *\n",
    "import sys\n",
    "import pickle\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (34130, 3)\n"
     ]
    }
   ],
   "source": [
    "file_dir = '../data/Ciao/'\n",
    "pos_file = open(file_dir+\"/positive_feedback_dataframe.pkl\",'rb')\n",
    "soc_file = open(file_dir+\"/social_positive_feedback_dataframe.pkl\",'rb')\n",
    "P = positive_df = pickle.load(pos_file)\n",
    "SP = social_positive_df = pickle.load(soc_file)\n",
    "print('data dimension: \\n', positive_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(data):\n",
    "    for col in ('item', 'user', 'rating'):\n",
    "        data[col] = data[col].astype('category')\n",
    "    \n",
    "    code_user = dict(zip(data['user'].cat.codes, data['user']))\n",
    "    user_code = dict(zip(data['user'], data['user'].cat.codes))\n",
    "    code_item = dict(zip(data['item'].cat.codes, data['item']))\n",
    "    item_code = dict(zip(data['item'], data['item'].cat.codes))\n",
    "    \n",
    "    mappings = {'code_user' : code_user, 'user_code' : user_code, 'code_item' : code_item, 'item_code' : item_code}\n",
    "\n",
    "    ratings = csr_matrix((data['rating'], (data['user'].cat.codes, data['item'].cat.codes)))\n",
    "    ratings.eliminate_zeros()\n",
    "    return ratings, data, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, df, mappings = create_matrix(positive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user item rating\n",
       "0    1    1      5\n",
       "1    2    1      5\n",
       "3    4    1      4\n",
       "4    5    1      4\n",
       "5    6    1      5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(model, ratings):\n",
    "    \"\"\"\n",
    "    computes area under the ROC curve (AUC).\n",
    "    The full name should probably be mean\n",
    "    auc score as it is computing the auc\n",
    "    for every user's prediction and actual\n",
    "    interaction and taking the average for\n",
    "    all users\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : BPR instance\n",
    "        Trained BPR model\n",
    "        \n",
    "    ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        sparse matrix of user-item interactions\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    auc : float 0.0 ~ 1.0\n",
    "    \"\"\"\n",
    "    auc = 0.0\n",
    "    \n",
    "    n_users, n_items = ratings.shape\n",
    "    for user, row in enumerate(ratings):\n",
    "        y_pred = model._predict_user(user)\n",
    "        y_true = np.zeros(n_items)\n",
    "        y_true[row.indices] = 1\n",
    "        auc += roc_auc_score(y_true, y_pred)\n",
    "    auc /= n_users\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(ratings, test_size = 0.2, seed = 1234):\n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    "\n",
    "    # Dictionary Of Keys based sparse matrix is more efficient\n",
    "    # for constructing sparse matrices incrementally compared with csr_matrix\n",
    "    train = ratings.copy().todok()\n",
    "    test = dok_matrix(train.shape)\n",
    "    \n",
    "    # for all the users assign randomly chosen interactions\n",
    "    # to the test and assign those interactions to zero in the training;\n",
    "    # when computing the interactions to go into the test set, \n",
    "    # remember to round up the numbers (e.g. a user has 4 ratings, if the\n",
    "    # test_size is 0.2, then 0.8 ratings will go to test, thus we need to\n",
    "    # round up to ensure the test set gets at least 1 rating)\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size = n_splits, replace = False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "    \n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2104x10768 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 29673 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = create_train_test(X, test_size = 0.1, seed = 20191004)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, P, SP):\n",
    "        self.P = P\n",
    "        self.SP = SP\n",
    "        \n",
    "    def static(self, social = False):\n",
    "        user = np.random.choice(self.P['user'])\n",
    "        \n",
    "        items = {}\n",
    "        \n",
    "        items['P'] = np.random.choice(self.P.query('user == @user')['item'])\n",
    "        tot_items = set(self.P['item'])\n",
    "        if social:\n",
    "            df_sp = list(self.SP.query('user == @user')['item'])\n",
    "            if(len(df_sp)):\n",
    "                items['SP'] = np.random.choice(df_sp)\n",
    "\n",
    "        \n",
    "        pos_items = []\n",
    "        for key in items:\n",
    "            pos_items.append(items[key])\n",
    "        \n",
    "        neg_items = list(tot_items - set(pos_items))\n",
    "                \n",
    "        items['N'] = np.random.choice(neg_items)\n",
    "        \n",
    "        return user, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mappings(code, key):\n",
    "    return code[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBPR1:\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking (BPR) for implicit feedback data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate : float, default 0.01\n",
    "        learning rate for gradient descent\n",
    "\n",
    "    n_factors : int, default 20\n",
    "        Number/dimension of user and item latent factors\n",
    "\n",
    "    n_iters : int, default 15\n",
    "        Number of iterations to train the algorithm\n",
    "        \n",
    "    batch_size : int, default 1000\n",
    "        batch size for batch gradient descent, the original paper\n",
    "        uses stochastic gradient descent (i.e., batch size of 1),\n",
    "        but this can make the training unstable (very sensitive to\n",
    "        learning rate)\n",
    "\n",
    "    reg : int, default 0.01\n",
    "        Regularization term for the user and item latent factors\n",
    "\n",
    "    seed : int, default 1234\n",
    "        Seed for the randomly initialized user, item latent factors\n",
    "\n",
    "    verbose : bool, default True\n",
    "        Whether to print progress bar while training\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    user_factors : 2d ndarray, shape [n_users, n_factors]\n",
    "        User latent factors learnt\n",
    "\n",
    "    item_factors : 2d ndarray, shape [n_items, n_factors]\n",
    "        Item latent factors learnt\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme \n",
    "    Bayesian Personalized Ranking from Implicit Feedback\n",
    "    - https://arxiv.org/abs/1205.2618\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate = 0.01, n_factors = 15, n_iters = 10, batch_size = 1, \n",
    "                 social_coefficient = 1, reg_u = 0.015, reg_i = 0.025, reg_k = 0.025, reg_j = 0.025, seed = 1234, verbose = True):\n",
    "        self.reg_u = reg_u\n",
    "        self.reg_i = reg_i\n",
    "        self.reg_k = reg_k\n",
    "        self.reg_j = reg_j\n",
    "        self.s_uk = social_coefficient\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # to avoid re-computation at predict\n",
    "        self._prediction = None\n",
    "        \n",
    "    def fit(self, ratings, sampler):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions\n",
    "        \"\"\"\n",
    "        n_users, n_items = ratings.shape\n",
    "        batch_size = self.batch_size\n",
    "        if n_users < batch_size:\n",
    "            batch_size = n_users\n",
    "            sys.stderr.write('WARNING: Batch size is greater than number of users,'\n",
    "                             'switching to a batch size of {}\\n'.format(n_users))\n",
    "\n",
    "        batch_iters = n_users // batch_size\n",
    "        \n",
    "        # initialize random weights\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.user_factors = rstate.normal(size = (n_users, self.n_factors))\n",
    "        self.item_factors = rstate.normal(size = (n_items, self.n_factors))\n",
    "        \n",
    "        # progress bar for training iteration if verbose is turned on\n",
    "        loop = range(self.n_iters)\n",
    "        if self.verbose:\n",
    "            loop = trange(self.n_iters, desc = self.__class__.__name__)\n",
    "        self.auc_scores = []\n",
    "        for _ in loop:\n",
    "            for _ in range(batch_iters):\n",
    "                user, items = sampler.static(True)\n",
    "                sampled_users = np.zeros(self.batch_size, dtype = np.int)\n",
    "                sampled_users[0] = get_mappings(mappings['user_code'], user)\n",
    "                \n",
    "                sampled_pos_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "                sampled_pos_items[0] = get_mappings(mappings['item_code'], items['P'])\n",
    "                \n",
    "                \n",
    "                sampled_soc_pos_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "                if 'SP' in items:\n",
    "                    sampled_soc_pos_items[0] = get_mappings(mappings['item_code'], items['SP'])\n",
    "                else:\n",
    "                    sampled_soc_pos_items[0] = -1\n",
    "                \n",
    "                \n",
    "                sampled_neg_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "                sampled_neg_items[0] = get_mappings(mappings['item_code'], items['N'])\n",
    "                \n",
    "                self._update(sampled_users, sampled_pos_items, sampled_soc_pos_items, sampled_neg_items)\n",
    "            self.auc_scores.append(auc_score(sbpr1, X_test))\n",
    "        return self\n",
    "    \n",
    "                \n",
    "    def _update(self, u, i, k ,j):\n",
    "        \"\"\"\n",
    "        update according to the bootstrapped user u, \n",
    "        positive item i and negative item j\n",
    "        \"\"\"\n",
    "        user_u = self.user_factors[u]\n",
    "        item_i = self.item_factors[i]\n",
    "        item_j = self.item_factors[j]\n",
    "        if k != -1:\n",
    "            item_k = self.item_factors[k]\n",
    "        else:\n",
    "            item_k = 0\n",
    "        # decompose the estimator, compute the difference between\n",
    "        # the score of the (positive and social items) and (social and negative items) ; \n",
    "\n",
    "        r_uij = np.sum(user_u * (item_i - item_j), axis = 1)\n",
    "        sigmoid_uij = np.exp(-r_uij) / (1.0 + np.exp(-r_uij))     # derivation of 1/(1+exp(-x))\n",
    "        \n",
    "        r_uik = np.sum(user_u*(item_i - item_k), axis = 1)/(1 + self.s_uk)\n",
    "        sigmoid_uik = np.exp(-r_uik) / (1.0 + np.exp(-r_uik))     # derivation of 1/(1+exp(-x))\n",
    "        \n",
    "        # repeat the 1 dimension sigmoid n_factors times so\n",
    "        # the dimension will match when doing the update\n",
    "        \n",
    "        sigmoid_uik_tiled = np.tile(sigmoid_uik, (self.n_factors, 1)).T\n",
    "        sigmoid_uij_tiled = np.tile(sigmoid_uij, (self.n_factors, 1)).T\n",
    "        \n",
    "\n",
    "        # update using gradient descent\n",
    "\n",
    "        grad_u = sigmoid_uik_tiled * ((item_k - item_i)/(1 + self.s_uk)) + sigmoid_uij_tiled * (item_j - item_i) + self.reg_u * user_u\n",
    "        grad_i = sigmoid_uik_tiled * (-user_u)/(1 + self.s_uk) + sigmoid_uij_tiled * (-user_u) + self.reg_i * item_i\n",
    "        grad_k = sigmoid_uik_tiled * (user_u/(1 + self.s_uk)) + self.reg_k * item_k\n",
    "        grad_j = (sigmoid_uij_tiled * user_u) + self.reg_j * item_j\n",
    "\n",
    "        \n",
    "        self.user_factors[u] -= self.learning_rate * grad_u\n",
    "        self.item_factors[i] -= self.learning_rate * grad_i\n",
    "        self.item_factors[k] -= self.learning_rate * grad_k\n",
    "        self.item_factors[j] -= self.learning_rate * grad_j\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Obtain the predicted ratings for every users and items\n",
    "        by doing a dot product of the learnt user and item vectors.\n",
    "        The result will be cached to avoid re-computing it every time\n",
    "        we call predict, thus there will only be an overhead the first\n",
    "        time we call it. Note, ideally you probably don't need to compute\n",
    "        this as it returns a dense matrix and may take up huge amounts of\n",
    "        memory for large datasets\n",
    "        \"\"\"\n",
    "        if self._prediction is None:\n",
    "            self._prediction = self.user_factors.dot(self.item_factors.T)\n",
    "\n",
    "        return self._prediction\n",
    "\n",
    "    def _predict_user(self, user):\n",
    "        \"\"\"\n",
    "        returns the predicted ratings for the specified user,\n",
    "        this is mainly used in computing evaluation metric\n",
    "        \"\"\"\n",
    "        user_pred = self.user_factors[user].dot(self.item_factors.T)\n",
    "        return user_pred\n",
    "    \n",
    "    def recommend(self, data, N = 5):\n",
    "        \"\"\"\n",
    "        Returns the top N ranked items for given user id,\n",
    "        excluding the ones that the user already liked\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions \n",
    "        \n",
    "        N : int, default 5\n",
    "            top-N similar items' N\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        recommendation : 2d ndarray, shape [number of users, N]\n",
    "            each row is the top-N ranked item for each query user\n",
    "        \"\"\"\n",
    "        n_users = data.shape[0]\n",
    "        recommendation = np.zeros((n_users, N))\n",
    "        scores = np.zeros((n_users, N))\n",
    "        users = []\n",
    "        ranks = []\n",
    "        for user in range(n_users):\n",
    "            users.append([user]*N)\n",
    "            ranks.append([i for i in range(1,N+1)])\n",
    "            topN_items, topN_scores = self.recommend_user(data, user, N)\n",
    "            recommendation[user], scores[user] = topN_items, topN_scores\n",
    "\n",
    "        return recommendation, scores, users, ranks\n",
    "    \n",
    "    def get_item_ratings(self, data, u):\n",
    "        \n",
    "        if u not in self.item_ratings:\n",
    "            items = data[u].indices\n",
    "            ratings = data[u].data\n",
    "            \n",
    "            self.item_ratings[u] = []\n",
    "            for i in range(len(items)):\n",
    "                self.item_ratings[u].append((items[i], ratings[i]))\n",
    "                \n",
    "        return self.item_ratings[u]\n",
    "        \n",
    "\n",
    "    def recommend_user(self, data, u, N, validation = True):\n",
    "        \"\"\"the top-N ranked items for a given user\"\"\"\n",
    "        scores = self._predict_user(u)\n",
    "\n",
    "        # compute the top N items, removing the items that the user already liked\n",
    "        # from the result and ensure that we don't get out of bounds error when \n",
    "        # we ask for more recommendations than that are available\n",
    "        liked = set(data[u].indices)\n",
    "        count = N + len(liked)\n",
    "        if count < scores.shape[0]:\n",
    "\n",
    "            # when trying to obtain the top-N indices from the score,\n",
    "            # using argpartition to retrieve the top-N indices in \n",
    "            # unsorted order and then sort them will be faster than doing\n",
    "            # straight up argort on the entire score\n",
    "            # http://stackoverflow.com/questions/42184499/cannot-understand-numpy-argpartition-output\n",
    "            ids = np.argpartition(scores, -count)[-count:]\n",
    "            best_ids = np.argsort(scores[ids])[::-1]\n",
    "            best = ids[best_ids]\n",
    "            best_scores = scores[best]\n",
    "        else:\n",
    "            best = np.argsort(scores)[::-1]\n",
    "            best_scores = scores[best]    \n",
    "\n",
    "        topN_items = []\n",
    "        topN_scores = []\n",
    "        for i in range(len(best)):\n",
    "            if best[i] not in liked:\n",
    "                topN_items.append(best[i])\n",
    "                topN_scores.append(best_scores[i])\n",
    "                \n",
    "        topN_items = list(islice((item for item in topN_items), N))\n",
    "        topN_scores = list(islice((score for score in topN_scores), N))\n",
    "        return topN_items, topN_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sample(positive_df, social_positive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "SBPR1:   0%|                                                                                                               | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1f6b629e7541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                 'n_factors': 10}\n\u001b[1;32m      9\u001b[0m \u001b[0msbpr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSBPR1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msbpr1_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msbpr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-af7d1af1def6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, ratings, sampler)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0msampled_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0msampled_users\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mappings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmappings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-86d61f78d924>\u001b[0m in \u001b[0;36mstatic\u001b[0;34m(self, social)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user == @user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msocial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   2842\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2843\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2844\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   2957\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resolvers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resolvers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/computation/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0meng_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_expr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massigner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/computation/engines.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_aligned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligned_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# make sure no names in resolvers and locals/globals clash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/computation/align.py\u001b[0m in \u001b[0;36m_align\u001b[0;34m(terms)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# perform the main alignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/computation/align.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(terms)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_result_type_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mterm_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/computation/align.py\u001b[0m in \u001b[0;36m_align_core\u001b[0;34m(terms)\u001b[0m\n\u001b[1;32m     64\u001b[0m                   if hasattr(term.value, 'axes')]\n\u001b[1;32m     65\u001b[0m     \u001b[0mterm_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterm_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# initial axes are the axes of the largest-axis'd term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, dtype)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Input is now list-like, so rely on \"standard\" construction:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# Now we just make sure the order is respected, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_ensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   4955\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4957\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntervalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mclosed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'closed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_interval_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIntervalDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIntervalDtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mconstruct_from_string\u001b[0;34m(cls, string)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mits\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpossible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \"\"\"\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"a string needs to be passed, got type {typ}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameters were randomly chosen\n",
    "sbpr1_params = {'reg_u': 0.025,\n",
    "                'reg_i': 0.025,\n",
    "                'reg_k' : 0.025,\n",
    "                'reg_j' : 0.025,\n",
    "                'learning_rate': 0.1,\n",
    "                'n_iters': 10,\n",
    "                'n_factors': 10}\n",
    "sbpr1 = SBPR1(**sbpr1_params)\n",
    "sbpr1.fit(X_train, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "auc = sbpr1.auc_scores\n",
    "x = range(len(auc))\n",
    "plt.plot(x,auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
